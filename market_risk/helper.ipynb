{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5bb849e9-0fa7-4091-b15c-78373a09847d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import numba as nb\n",
    "from math import exp\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "import statsmodels.api as sm\n",
    "import scipy.stats as stats\n",
    "from scipy.optimize import minimize\n",
    "from arch import arch_model\n",
    "from pmdarima.model_selection import train_test_split\n",
    "\n",
    "def get_data(list_of_stocks: list, start_date:str, end_date:str , columns:list, interval:str, resample=None) -> pd.DataFrame:\n",
    "    lst_returns = []\n",
    "    lst_log_returns = []\n",
    "    for stock in list_of_stocks:\n",
    "        equity=yf.Ticker(stock)\n",
    "        equity_data=equity.history(start=start_date, end=end_date, interval=interval)\n",
    "        if resample != None:\n",
    "            equity_data = equity_data.resample(resample).last()\n",
    "        equity_data['returns']=equity_data['Close'].pct_change()\n",
    "        equity_data['log_returns'] = np.log(equity_data['Close'].shift(1)) - np.log(equity_data['Close'])\n",
    "        a = equity_data['returns']\n",
    "        b = equity_data[\"log_returns\"]\n",
    "        lst_returns.append(a)\n",
    "        lst_log_returns.append(b)\n",
    "    \n",
    "    #simple returns\n",
    "    df = pd.concat(lst_returns, axis=1, join= 'outer')\n",
    "    df.columns= columns\n",
    "    df.dropna(axis=0,inplace=True)\n",
    "    \n",
    "    #log returns\n",
    "    df_lr = pd.concat(lst_log_returns, axis=1, join= 'outer')\n",
    "    df_lr.columns= columns\n",
    "    df_lr.dropna(axis=0,inplace=True)\n",
    "    \n",
    "    return df, df_lr\n",
    "\n",
    "get_data_nb = nb.jit(get_data)\n",
    "\n",
    "#### bet sizing\n",
    "def half_kelly_Thorp(rf:float, returns: pd.DataFrame, stocks: list) -> np.array:\n",
    "    excess_returns = returns - rf\n",
    "    sizing = np.linalg.inv(excess_returns.cov().to_numpy()*len(stocks)) @ (excess_returns.mean().to_numpy()*len(stocks))\n",
    "    return sizing/2\n",
    "        \n",
    "def losses(p : pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    :param p: portfolio time series\n",
    "    :return: portfolio losses (returns) in absolute value\n",
    "    \"\"\"\n",
    "    return p.where(p < 0).dropna().abs()\n",
    "\n",
    "def gains(p: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    :param p: portfolio time series\n",
    "    :return: portfolio gains (returns)\n",
    "    \"\"\"\n",
    "    return p.where(p > 0).dropna()\n",
    "\n",
    "#### risk metrics\n",
    "def non_parametric_VAR(p:pd.Series, q:float) -> float:\n",
    "    \"\"\"\n",
    "    :param p: portfolio\n",
    "    :param q: quantile\n",
    "    :return: Value at risk of the portfolio\n",
    "    \"\"\"\n",
    "    return p.quantile(q)\n",
    "\n",
    "def non_parametric_ES(p: pd.DataFrame, q: float):\n",
    "    \"\"\"\n",
    "    :param p: portfolio\n",
    "    :param q: quantile\n",
    "    :return: Conditional value at risk E(X1| X1 <= VAR(X))\n",
    "    \"\"\"\n",
    "    return p.where(p >= non_parametric_VAR(p, q)).dropna().mean()\n",
    "\n",
    "\n",
    "def present_risk_metric(description, metric_func, **kwargs) -> str:\n",
    "    \n",
    "    print(\"The \" + description + f\" is: {round(metric_func(**kwargs)*100, 4)}%\")\n",
    "\n",
    "\n",
    "### parametric with normal distribution\n",
    "def parametric_var(p: pd.DataFrame, weights: list, alpha: float) -> float:\n",
    "    \"\"\"\n",
    "    :param p: portfolio returns\n",
    "    :param alpha: significance level\n",
    "    :param weights: portfolio weights\n",
    "    :return: Parametric Var\n",
    "    \"\"\"\n",
    "    std = np.sqrt(weights.T @ p.cov() @ weights)\n",
    "    return  std * stats.norm.ppf(1-alpha)\n",
    "    \n",
    "def parametric_expected_shortfall(p: pd.DataFrame, weights: list, alpha: float) -> float:\n",
    "    \"\"\"\n",
    "    :param p: portfolio returns\n",
    "    :param alpha: significance level\n",
    "    :param weights: portfolio weights\n",
    "    :return: Parametric ES\n",
    "    \"\"\"\n",
    "    std = np.sqrt(weights.T @ p.cov() @ weights)  \n",
    "    return  std * stats.norm.pdf(stats.norm.ppf(1-alpha))/(alpha)\n",
    "    \n",
    "#### parametric with student t\n",
    "def neg_log_likelihood(params: list, returns:pd.Series) -> float:\n",
    "    df, loc, scale = params\n",
    "    return -stats.t.logpdf(returns, df, loc, scale).sum()\n",
    "\n",
    "def obtain_parameters(guess: list, returns:pd.Series) -> tuple:\n",
    "    \"\"\"\n",
    "    :param guess: [0, 1, 0], our guess to the parameters of student t distribution\n",
    "    :return: Degrees of Freedom, Location, Scale:\n",
    "    \"\"\"\n",
    "    return minimize(neg_log_likelihood, guess, args=(returns, ), method='Nelder-Mead').x\n",
    "#### risk metrics EVT\n",
    "\n",
    "\n",
    "#### plots\n",
    "def correlation_matrix(p: pd.DataFrame, stocks:list) -> sns.heatmap:\n",
    "    # create correlation matrix\n",
    "    corr_matrix = p[stocks].corr()\n",
    "    # Generate a mask for the upper triangle\n",
    "    mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
    "    # Generate a custom diverging colormap\n",
    "    cmap = sns.color_palette(\"coolwarm\", as_cmap=True)\n",
    "    \n",
    "    plt.figure(figsize=(8, 8))\n",
    "    \n",
    "    sns.heatmap(corr_matrix, mask = mask, cmap = cmap, square = True, annot = True, cbar_kws  = {\"shrink\": .4})\n",
    "    plt.show()\n",
    "        \n",
    "\n",
    "def MSplot(data, p=4):\n",
    "    x = data.abs()\n",
    "    fig, axs = plt.subplots(nrows=int(p/2), ncols=2, figsize=(8, 6))\n",
    "    r = []\n",
    "    for i in range(1, p + 1):\n",
    "        y = x**i\n",
    "        S = y.cumsum()\n",
    "        M = y.cummax()\n",
    "        r.append(M/S)\n",
    "    \n",
    "    axs[0, 0].plot(range(len(x)), r[0], color=\"orangered\")\n",
    "    axs[0, 0].set_title(\"MS plot, p=1\")\n",
    "    axs[0, 0].set_xlabel(\"n\")\n",
    "    axs[0, 0].set_ylabel(\"Rn\")\n",
    "    axs[0, 1].plot(range(len(x)), r[1], color =\"orangered\")\n",
    "    axs[0, 1].set_xlabel(\"n\")\n",
    "    axs[0, 1].set_title(\"MS plot, p=2\")\n",
    "    axs[1, 0].plot(range(len(x)), r[2], color=\"orangered\")\n",
    "    axs[1, 0].set_xlabel(\"n\")\n",
    "    axs[1, 0].set_ylabel(\"Rn\")\n",
    "    axs[1, 0].set_title(\"MS plot, p=3\")\n",
    "    axs[1, 1].plot(range(len(x)), r[3], color=\"orangered\")\n",
    "    axs[1, 1].set_xlabel(\"n\")\n",
    "    axs[1, 1].set_title(\"MS plot, p=4\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "def ACF(**kwargs):\n",
    "    sm.graphics.tsa.plot_acf(**kwargs)\n",
    "    plt.xlabel('Lags')\n",
    "    plt.ylabel('Autocorrelation')\n",
    "    plt.title('Autocorrelation Function (ACF)')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def PACF(**kwargs):\n",
    "    sm.graphics.tsa.plot_pacf(**kwargs)\n",
    "    plt.xlabel('Lags')\n",
    "    plt.ylabel('Partial Autocorrelation')\n",
    "    plt.title('Partial Autocorrelation Function (PACF)')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def qqplot(**kwargs):\n",
    "    sm.qqplot(**kwargs)\n",
    "    plt.title(\"QQ Plot\")\n",
    "    plt.xlabel(\"Theoretical Quantiles\")\n",
    "    plt.ylabel(\"Sample Quantiles\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def vol_plot(returns: pd.Series, y_series: pd.Series, yhat: pd.Series, port_description: str) -> plt.plot:\n",
    "    fig,ax = plt.subplots(figsize=(10,8))\n",
    "    ax.spines[['top','right']].set_visible(False)\n",
    "    # Plot test set returns\n",
    "    plt.plot(returns[-y_test.shape[0]:])\n",
    "    # Plot volatility estimates for test set\n",
    "    plt.plot(y_test.index, np.sqrt(yhat.variance.values[-1,:]))\n",
    "    plt.title(f'{port_description} Volatility Prediction')\n",
    "    plt.legend(['True Daily Log Returns', 'Predicted Volatility'])\n",
    "    plt.show()\n",
    "    \n",
    "def vols_plot(returns: pd.Series, y_test: pd.Series, yhat: pd.Series, rolling_preds: pd.Series, port_description: str) -> plt.plot:\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 8))\n",
    "    ax1.spines[['top','right']].set_visible(False)\n",
    "    ax1.plot(returns[-y_test.shape[0]:])\n",
    "    ax1.plot(y_test.index, np.sqrt(yhat.variance.values[-1,:]))\n",
    "    ax1.set_title(f\"{port_description} Volatility N-Step Predictions\")\n",
    "    ax1.legend(['True Daily Returns', 'Predicted Volatility'])\n",
    "    \n",
    "    ax.spines[['top','right']].set_visible(False)\n",
    "    ax2.plot(returns[-y_test.shape[0]:])\n",
    "    ax2.plot(y_test.index,rolling_preds)\n",
    "    ax2.set_title(f\"{port_description} Volatility Rolling Predictions\")\n",
    "    ax2.legend(['True Daily Returns', 'Predicted Rolling Volatility'])\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "### performance metrics\n",
    "\n",
    "def cagr(f_v:float, i_v:float, t:float) -> str:\n",
    "    \"\"\"\n",
    "    Parameters: \n",
    "    f_v: final value of the strategy\n",
    "    i_v: initial value of the strategy\n",
    "    t: time in years\n",
    "    return: Compound annual growth rate of the strategy \n",
    "    \"\"\"\n",
    "    CAGR = round(((f_v/i_v)**(1/t) - 1)*100, 2)\n",
    "    return \"CAGR of: \" + str(CAGR) + \" %\", CAGR\n",
    "\n",
    "def sharpe(rf, returns):\n",
    "    return round((returns.mean() - rf/252) / returns.std(), 2)\n",
    "    \n",
    "\n",
    "def calculateMaxDD(cumret):\n",
    "    \"\"\"\n",
    "    Parameters: cumret is the a compounded cumulative return.\n",
    "    returns : maximum drawdown, maximum drawdown duration, index of the day of MDD  \n",
    "    \"\"\"\n",
    "\n",
    "    highwatermark=np.zeros(cumret.shape)\n",
    "    drawdown=np.zeros(cumret.shape)\n",
    "    drawdownduration=np.zeros(cumret.shape)\n",
    "    \n",
    "    for t in np.arange(1, cumret.shape[0]):\n",
    "        highwatermark[t]=np.maximum(highwatermark[t-1], cumret[t])\n",
    "        drawdown[t]=(1+cumret[t])/(1+highwatermark[t])-1\n",
    "        if drawdown[t]==0:\n",
    "            drawdownduration[t]=0\n",
    "        else:\n",
    "            drawdownduration[t]=drawdownduration[t-1]+1\n",
    "             \n",
    "    maxDD, i=np.min(drawdown), np.argmin(drawdown) # drawdown < 0 always\n",
    "    maxDDD=np.max(drawdownduration)\n",
    "    return round(maxDD, 2), int(maxDDD), i\n",
    "\n",
    "#### presentation\n",
    "def rounder(lista:list, n:int) -> list:\n",
    "    return [str(round(ele*100, 4))+ \"%\" for ele in lista]\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
